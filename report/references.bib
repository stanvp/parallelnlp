@Article{berger_a1-etal:1996a,
  author =	"Adam L. Berger and Stephen A. Della Pietra and Vincent
		 J. Della Pietra",
  title =	"A Maximum Entropy Approach to Natural Language
		 Processing",
  journal =	"Computational Linguistics",
  year = 	"1996",
  volume =	"22",
  number =	"1",
  pages =	"39--71",
  topic =	"statistical-nlp;maximum-entropy;",
}

@InProceedings{conf/nips/MannMMSW09,
  title =	"Efficient Large-Scale Distributed Training of
		 Conditional Maximum Entropy Models",
  author =	"Gideon Mann and Ryan T. McDonald and Mehryar Mohri and
		 Nathan Silberman and Dan Walker",
  bibdate =	"2011-11-10",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/nips/nips2009.html#MannMMSW09",
  booktitle =	"NIPS",
  booktitle =	"Advances in Neural Information Processing Systems 22:
		 23rd Annual Conference on Neural Information Processing
		 Systems 2009. Proceedings of a meeting held 7-10
		 December 2009, Vancouver, British Columbia, Canada",
  publisher =	"Curran Associates, Inc",
  year = 	"2009",
  editor =	"Yoshua Bengio and Dale Schuurmans and John D. Lafferty
		 and Christopher K. I. Williams and Aron Culotta",
  ISBN = 	"9781615679119",
  pages =	"1231--1239",
  URL =  	"http://books.nips.cc/papers/files/nips22/NIPS2009_0345.pdf",
}

@InProceedings{Ganchev98smallstatistical,
    author = {Kuzman Ganchev and Mark Dredze},
    title = {Small statistical models by random feature mixing},
    booktitle = {In workshop on Mobile NLP at ACL, 2008. Indyk and},
    year = {1998},
    pages = {604--613}
}

@Misc{oai:infoscience.epfl.ch:165111,
  title =	"Parallelizing Machine Learning- Functionally: {A}
		 Framework and Abstractions for Parallel Graph
		 Processing",
  author =	"Philipp Haller and Heather Miller",
  year = 	"2011",
  abstract =	"Implementing machine learning algorithms for large
		 data, such as the Web graph and social networks, is
		 challenging. Even though much research has focused on
		 making sequential algorithms more scalable, their
		 running times continue to be prohibitively long.
		 Meanwhile, parallelization remains a formidable
		 challenge for this class of problems, despite
		 frameworks like MapReduce which hide much of the
		 associated complexity. We present a framework for
		 implementing parallel and distributed machine learning
		 algorithms on large graphs, flexibly, through the use
		 of functional programming abstractions. Our aim is a
		 system that allows researchers and practitioners to
		 quickly and easily implement (and experiment with)
		 their algorithms in a parallel or distributed setting.
		 We introduce functional combinators for the flexible
		 composition of parallel, aggregation, and sequential
		 steps. To the best of our knowledge, our system is the
		 first to avoid inversion of control in a (bulk)
		 synchronous parallel model.",
  bibsource =	"OAI-PMH server at infoscience.epfl.ch",
  language =	"en",
  oai =  	"oai:infoscience.epfl.ch:165111",
  subject =	"Parallel programming; distributed programming; machine
		 learning; graph processing",
  URL =  	"http://infoscience.epfl.ch/record/165111",
}

@InProceedings{Rennie03,
  author =	"Jason Rennie and Lawrence Shih and Jaime Teevan and
		 David Karger",
  title =	"Tackling the Poor Assumptions of Naive Bayes Text
		 Classifiers",
  booktitle =	"Proceedings of ICML-03, 20th International Conference
		 on Machine Learning",
  year = 	"2003",
  address =	"Washington, DC",
  publisher =	"Morgan Kaufmann Publishers, San Francisco, US",
  URL =  	"http://www.ai.mit.edu/~jrennie/papers/icml03-nb.pdf",
  abstract =	"Naive Bayes is often used as a baseline in text
		 classification because it is fast and easy to
		 implement. Its severe assumptions make such efficiency
		 possible but also adversely affect the quality of its
		 results. In this paper we propose simple, heuristic
		 solutions to some of the problems with Naive Bayes
		 classifiers, addressing both systemic issues as well as
		 problems that arise because text is not actually
		 generated according to a multinomial model. We find
		 that our simple corrections result in a fast algorithm
		 that is competitive with state-of-the-art text
		 classification algorithms such as the Support Vector
		 Machine.",
}

@Misc{oai:CiteSeerPSU:93050,
  title =	"Using Maximum Entropy for Text Classification",
  author =	"Kamal Nigam and John Lafferty and Andrew Mccallum",
  year = 	"1999",
  month =	apr # "~29",
  abstract =	"This paper proposes the use of maximum entropy
		 techniques for text classification. Maximum entropy is
		 a probability distribution estimation technique widely
		 used for a variety of natural language tasks, such as
		 language modeling, part-of-speech tagging, and text
		 segmentation. The underlying principle of maximum
		 entropy is that without external knowledge, one should
		 prefer distributions that are uniform. Constraints on
		 the distribution, derived from labeled training data,
		 inform maximum entropy where to be minimally
		 non-uniform. The maximum entropy formulation has a
		 unique solution which can be found by the improved
		 iterative scaling algorithm. In text classification
		 tasks, maximum entropy is used to estimate the
		 conditional distribution of the class variable given
		 the document. Experiments on several text datasets show
		 that maximum entropy performance is sometimes
		 significantly better, but also sometimes worse, than
		 naive Bayes text classification. Much future work
		 remains, though the ...",
  citeseer-references = "oai:CiteSeerPSU:44611; oai:CiteSeerPSU:585943;
		 oai:CiteSeerPSU:79078; oai:CiteSeerPSU:140776;
		 oai:CiteSeerPSU:124233; oai:CiteSeerPSU:222851;
		 oai:CiteSeerPSU:107422; oai:CiteSeerPSU:553162;
		 oai:CiteSeerPSU:489994; oai:CiteSeerPSU:14059;
		 oai:CiteSeerPSU:555479; oai:CiteSeerPSU:581830;
		 oai:CiteSeerPSU:31701; oai:CiteSeerPSU:276280;
		 oai:CiteSeerPSU:27904; oai:CiteSeerPSU:98225;
		 oai:CiteSeerPSU:93679",
  annote =	"Andrew Mccallum (; School of Computer Science;
		 Carnegie Mellon University; Just Research; ; Pittsburgh
		 , PA 15213; 4616 Henry Street; Pittsburgh , PA
		 15213);",
  bibsource =	"OAI-PMH server at cs1.ist.psu.edu",
  language =	"en",
  oai =  	"oai:CiteSeerPSU:93050",
  rights =	"unrestricted",
  URL =  	"http://citeseer.ist.psu.edu/93050.html;
		 http://www.cs.cmu.edu/~knigam/papers/maxent.ps",
}

@InProceedings{yang97,
  author =	"Yiming Yang and Jan O. Pedersen",
  title =	"A Comparative Study on Feature Selection in Text
		 Categorization",
  booktitle =	"International Conference on Machine Learning",
  pages =	"412--420",
  year = 	"1997",
  URL =  	"citeseer.nj.nec.com/yang97comparative.html",
}

@Book{Croft:2010:SEI,
  author =	"W. Bruce Croft and Donald Metzler and Trevor
		 Strohman",
  title =	"Search engines: information retrieval in practice",
  publisher =	"Pearson Education",
  address =	"Boston, MA, USA",
  pages =	"xxv + 524",
  year = 	"2010",
  ISBN = 	"0-13-136489-8 (paperback)",
  isbn-13 =	"978-0-13-136489-9 (paperback)",
  LCCN = 	"TK5105.884 CRO 2010",
  bibdate =	"Thu May 5 19:23:28 MDT 2011",
  bibsource =	"http://www.math.utah.edu/pub/tex/bib/compj2010.bib;
		 library.ox.ac.uk:210/ADVANCE",
  acknowledgement = "Nelson H. F. Beebe, University of Utah, Department
		 of Mathematics, 110 LCB, 155 S 1400 E RM 233, Salt Lake
		 City, UT 84112-0090, USA, Tel: +1 801 581 5254, FAX: +1
		 801 581 4148, e-mail: \path|beebe@math.utah.edu|,
		 \path|beebe@acm.org|, \path|beebe@computer.org|
		 (Internet), URL:
		 \path|http://www.math.utah.edu/~beebe/|",
  subject =	"Search engines; Information storage and retrieval
		 systems; Information retrieval",
}

@Book{manning99,
  title =	"{F}oundations of {S}tatistical {N}atural {L}anguage
		 {P}rocessing",
  publisher =	"{MIT} {P}ress",
  year = 	"1999",
  author =	"Christopher Manning and Hinrich Sch{\"u}tze",
  address =	"Cambridge, MA",
  topics =	"source:serge",
}

@article{Dean:2008:MSD:1327452.1327492,
 author = {Dean, Jeffrey and Ghemawat, Sanjay},
 title = {MapReduce: simplified data processing on large clusters},
 journal = {Commun. ACM},
 issue_date = {January 2008},
 volume = {51},
 issue = {1},
 month = jan,
 year = {2008},
 issn = {0001-0782},
 pages = {107--113},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1327452.1327492},
 doi = {http://doi.acm.org/10.1145/1327452.1327492},
 acmid = {1327492},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@InProceedings{conf/nips/ChuKLYBNO06,
  title =	"Map-Reduce for Machine Learning on Multicore",
  author =	"Cheng-Tao Chu and Sang Kyun Kim and Yi-An Lin and
		 YuanYuan Yu and Gary R. Bradski and Andrew Y. Ng and
		 Kunle Olukotun",
  publisher =	"MIT Press",
  year = 	"2006",
  bibdate =	"2007-10-25",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/nips/nips2006.html#ChuKLYBNO06",
  booktitle =	"NIPS",
  editor =	"Bernhard Sch{\"o}lkopf and John C. Platt and Thomas
		 Hoffman",
  ISBN = 	"0-262-19568-2",
  pages =	"281--288",
  URL =  	"http://books.nips.cc/papers/files/nips19/NIPS2006_0725.pdf",
}

@InProceedings{berger:gental,
  title =	"The Improved Iterative Scaling Algorithm: {A} Gentle
		 Introduction",
  author =	"Adam Berger",
  year = 	"1997",
  month =	jan # "~13",
  citeseer-references = "oai:CiteSeerPSU:585943;
		 oai:CiteSeerPSU:222851",
  bibsource =	"OAI-PMH server at cs1.ist.psu.edu",
  description =  "this document should be sent to aberger@cs.cmu.edu.
		 ffl Z (x) is a normalizing factor, required to make p a
		 probability distribution: Z (x) =",
  language =	"en",
  oai =  	"oai:CiteSeerPSU:31826",
  rights =	"unrestricted",
  URL =  	"http://citeseer.ist.psu.edu/31826.html;
		 http://www.cs.cmu.edu/afs/cs/user/aberger/www/ps/scaling.ps",
}

@InProceedings{scalaparallel,
    author  = "Philipp Haller",
    title   = "The Many Flavors of Parallel Programming in Scala",
    publisher = "Presented at Scalathon 2011 at the University of Pennsylvania in Philadelphia",
    year    = 2011,
    URL     = "http://lamp.epfl.ch/~phaller/doc/Scalathon2011.pdf"
}
